import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
!pip install xgboost
import xgboost as xgb
from sklearn.model_selection import RandomizedSearchCV
import seaborn as sns
get_ipython().system('pip install matlibplot')
#loading the data into a pandas dataframe
df = pd.read_csv('dataset-kidney-stone.csv')

df.head()

# Examine the distribution of each feature and handle outliers

def remove_outliers(df, col):
    q1 = df[col].quantile(0.25)
    q3 = df[col].quantile(0.75)
    iqr = q3 - q1
    upper = q3 + 1.5*iqr
    lower = q1 - 1.5*iqr
    df = df[(df[col] >= lower) & (df[col] <= upper)]
    return df

sns.boxplot(data=df[df.columns])
plt.title("Outliers before handling")
plt.show()
df = remove_outliers(df, df.columns)
sns.boxplot(data=df[df.columns])
plt.title("Outliers after handling")
plt.show()

# For example, if a feature is skewed or has outliers, we can apply a transformation or remove the outliers

sns.distplot(df['gravity'])
sns.distplot(df['ph'])
sns.distplot(df['osmo'])
sns.distplot(df['cond'])
sns.distplot(df['urea'])
sns.distplot(df['calc'])
sns.distplot(df['target'])

# Standardize the data
scaler = StandardScaler()
X = scaler.fit_transform(df.drop('cond', axis=1))
y = df['cond']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train an XGBoost model
xgb_model = xgb.XGBRegressor(random_state=42)
xgb_model.fit(X_train, y_train)

# Evaluate the performance of the XGBoost model on the testing set
pred = xgb_model.predict(X_train)
mae = mean_absolute_error(y_train, pred)
mse = mean_squared_error(y_train, pred)
r2 = r2_score(y_train, pred)

print("testing MAE:", mae)
print("testing MSE:", mse)
print("testing R^2:", r2)

y_pred = xgb_model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("training MAE:", mae)
print("training MSE:", mse)
print("training R^2:", r2)
      
# Set up a random search CV object and define the hyperparameter grid to search over
params = {
    "learning_rate": [0.05, 0.1, 0.15],
    "max_depth": [3, 4, 5],
    "n_estimators": [100, 500, 1000],
    "colsample_bytree": [0.3, 0.6, 0.8],
    "gamma": [0, 0.1, 0.3]
}

xgb_model_cv = xgb.XGBRegressor(random_state=42)
random_search = RandomizedSearchCV(xgb_model_cv, param_distributions=params, n_iter=5, cv=5, n_jobs=-1, random_state=42)
random_search.fit(X_train, y_train)
xgb_best_model=random_search.best_estimator_
      
# Train the XGBoost model with the best hyperparameters on the entire dataset
#xgb_model_best = xgb.XGBRegressor(**random_search.best_params_, random_state=42)
xgb_model_best.fit(X, y)

# Evaluate the performance of the XGBoost model with the best hyperparameters on the entire dataset
pred = xgb_model_best.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("after tuning testing MAE:", mae)
print("after tuning testing MSE:", mse)
print("after tuning testing R^2:", r2)
    
pred = xgb_model_best.predict(X_train)
mae = mean_absolute_error(y_train, pred)
mse = mean_squared_error(y_train, pred)
r2 = r2_score(y_train, pred)

print("after tuning training MAE:", mae)
print("after tuning training MSE:", mse)
print("after tuning training R^2:", r2)
